{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f34f7e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ac2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb142c5",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fed750",
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_WATERFALL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import ClifOrchestrator\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "from clifpy.utils.unit_converter import convert_dose_units_by_med_category\n",
    "from clifpy.utils.config import get_config_or_params\n",
    "from clifpy.utils import apply_outlier_handling\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "CONFIG_PATH=\"config/config.json\"\n",
    "co = ClifOrchestrator(config_path=CONFIG_PATH)\n",
    "\n",
    "# Ensure the output subdirs exists\n",
    "os.makedirs(\"output/intermediate\", exist_ok=True)\n",
    "os.makedirs(\"output/final\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_config_or_params(CONFIG_PATH)\n",
    "SITE_NAME = cfg['site_name'].lower()\n",
    "print(SITE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "CURRENT_TIME_STR = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fd20c",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ae278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query_from_file(sql_file_path: str) -> duckdb.DuckDBPyRelation:\n",
    "    \"\"\"\n",
    "    Loads a query from a .sql file and executes it using the given DuckDB connection.\n",
    "\n",
    "    Args:\n",
    "        con: An active DuckDB connection.\n",
    "        sql_file_path: The absolute path to the .sql file.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with the results of the query.\n",
    "    \"\"\"\n",
    "    print(f\"--- Loading and executing query from {sql_file_path} ---\")\n",
    "    \n",
    "    # Read the entire content of the .sql file\n",
    "    query = Path(sql_file_path).read_text()\n",
    "\n",
    "    # Execute the query and return as a pandas DataFrame\n",
    "    result = duckdb.sql(query)\n",
    "\n",
    "    print(\"Query executed successfully.\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day_shift_id(df: pd.DataFrame, timestamp_name = 'event_dttm') -> pd.DataFrame:\n",
    "    df['_dh'] = df[timestamp_name].dt.floor('h', ambiguous='NaT')\n",
    "    df['_hr'] = df[timestamp_name].dt.hour\n",
    "    q = \"\"\"\n",
    "    WITH day_starts AS (\n",
    "        FROM df\n",
    "        SELECT *\n",
    "            , _shift: CASE WHEN _hr >= 7 AND _hr < 19 THEN 'day' ELSE 'night' END\n",
    "            , _is_day_start: CASE\n",
    "                WHEN _hr = 7 AND COALESCE(LAG(_hr) OVER w, -1) != 7 THEN 1\n",
    "                ELSE 0 END\n",
    "        WINDOW w AS (PARTITION BY hospitalization_id ORDER BY _dh)       \n",
    "    )\n",
    "    FROM day_starts\n",
    "    -- INNER JOIN cohort_hosp_ids_df USING (hospitalization_id)\n",
    "    SELECT *\n",
    "        , _nth_day: SUM(_is_day_start) OVER w\n",
    "        , _day_shift: 'day' || _nth_day::INT::TEXT || '_' || _shift\n",
    "    WINDOW w AS (PARTITION BY hospitalization_id ORDER BY _dh)       \n",
    "    ORDER BY hospitalization_id, _dh\n",
    "    \"\"\"\n",
    "    return duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_meds_duplicates(meds_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM meds_df\n",
    "    QUALIFY ROW_NUMBER() OVER (\n",
    "        PARTITION BY hospitalization_id, admin_dttm, med_category\n",
    "        ORDER BY \n",
    "            -- apply mar action dedup logic\n",
    "            CASE WHEN mar_action_category IS NULL THEN 10\n",
    "                WHEN mar_action_category in ('verify', 'not_given') THEN 9\n",
    "                WHEN mar_action_category = 'stop' THEN 8\n",
    "                WHEN mar_action_category = 'going' THEN 7\n",
    "                ELSE 1 END,\n",
    "            -- if tied at the same mar action, deprioritize zero or null doses\n",
    "            CASE WHEN med_dose > 0 THEN 1\n",
    "                ELSE 2 END,\n",
    "            -- prioritize larger doses\n",
    "            med_dose DESC \n",
    "    ) = 1\n",
    "    ORDER BY hospitalization_id, med_category, admin_dttm;\n",
    "    \"\"\"\n",
    "    return duckdb.sql(query).to_df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c98ac3",
   "metadata": {},
   "source": [
    "# Cohort ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import Adt, Hospitalization\n",
    "\n",
    "adt = Adt.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = ['hospitalization_id', 'in_dttm', 'out_dttm', 'location_category'],\n",
    "    filters = {\n",
    "        'location_category': ['icu']\n",
    "    }\n",
    "    )\n",
    "\n",
    "hosp_ids_w_icu_stays = adt.df['hospitalization_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy.utils.stitching_encounters import stitch_encounters\n",
    "\n",
    "# Load your dataframes\n",
    "hosp_w_icu_stays = Hospitalization.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    filters = {\n",
    "        'hospitalization_id': hosp_ids_w_icu_stays\n",
    "    }\n",
    ")\n",
    "adt_w_icu_stays = Adt.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    filters = {\n",
    "        'hospitalization_id': hosp_ids_w_icu_stays\n",
    "    }\n",
    "    # columns = ['hospitalization_id', 'in_dttm', 'out_dttm', 'location_category'],\n",
    "    )\n",
    "\n",
    "# Perform stitching\n",
    "hosp_stitched, adt_stitched, encounter_mapping = stitch_encounters(\n",
    "    hospitalization=hosp_w_icu_stays.df,\n",
    "    adt=adt_w_icu_stays.df,\n",
    "    time_interval=12  # 12-hour window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41723cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import RespiratorySupport\n",
    "\n",
    "resp_processed_path = f\"output/intermediate/{SITE_NAME}_resp_processed_bf.parquet\"\n",
    "\n",
    "if not os.path.exists(resp_processed_path) or RERUN_WATERFALL:\n",
    "    cohort_resp = RespiratorySupport.from_file(\n",
    "        config_path=CONFIG_PATH,\n",
    "        columns = [\n",
    "            'hospitalization_id', 'recorded_dttm', 'device_name', 'device_category',\n",
    "            'mode_name', 'mode_category', 'fio2_set', 'peep_set', 'pressure_support_set',\n",
    "            'resp_rate_set', 'tidal_volume_set', 'peak_inspiratory_pressure_set', 'tracheostomy'\n",
    "            ],\n",
    "        filters = {\n",
    "            'hospitalization_id': hosp_ids_w_icu_stays\n",
    "        }\n",
    "    )\n",
    "    apply_outlier_handling(cohort_resp, outlier_config_path = 'config/outlier_config.yaml')\n",
    "    cohort_resp_p = cohort_resp.waterfall(bfill=True)\n",
    "    cohort_resp_p.df.to_parquet(resp_processed_path)\n",
    "    resp_p = cohort_resp_p.df\n",
    "else:\n",
    "    print(f\"Loading {resp_processed_path}\")\n",
    "    resp_p = pd.read_parquet(resp_processed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d45c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_p['tracheostomy'] = resp_p['tracheostomy'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7843f56",
   "metadata": {},
   "source": [
    "## Time grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_streaks = run_query_from_file('code/cohort_id.sql').df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the observation-window hourly time grids\n",
    "# start and end time for each hospitalization_id is the start and end of the first IMV streak of 24 hours or longer\n",
    "# the end of the imv streak means extubation, which we evaulates whether as successful or not\n",
    "\n",
    "q = \"\"\"\n",
    "FROM all_streaks\n",
    "SELECT hospitalization_id, _streak_id, _start_dttm, _end_dttm, _duration_hrs\n",
    "WHERE _at_least_24h = 1 -- has to last for at least 24 hours\n",
    "    AND _on_imv = 1 -- has to be an IMV streak\n",
    "    AND _streak_id = 1 -- has to bethe first IMV streak\n",
    "\"\"\"\n",
    "cohort_imv_streaks_f = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_hosp_ids = cohort_imv_streaks_f['hospitalization_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_imv_streaks_f['_start_hr'] = cohort_imv_streaks_f['_start_dttm'].dt.floor('h', ambiguous='NaT')\n",
    "cohort_imv_streaks_f['_end_hr'] = cohort_imv_streaks_f['_end_dttm'].dt.ceil('h', ambiguous='NaT')\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT \n",
    "    hospitalization_id,\n",
    "    unnest(generate_series(_start_hr, _end_hr, INTERVAL '1 hour')) AS event_dttm\n",
    "FROM cohort_imv_streaks_f\n",
    "ORDER BY hospitalization_id, event_dttm\n",
    "\"\"\"\n",
    "cohort_hrly_grids = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206523b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_hrly_grids_f = add_day_shift_id(cohort_hrly_grids)\n",
    "assert len(cohort_hrly_grids_f) == len(cohort_hrly_grids), 'length altered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f55a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_shift_change_grids = cohort_hrly_grids_f[cohort_hrly_grids_f['_hr'].isin([7, 19])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e4f8c",
   "metadata": {},
   "source": [
    "## Exclude: neuromuscular blocking agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd25de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import MedicationAdminContinuous\n",
    "\n",
    "# neuromuscular blocking agent\n",
    "nmb = MedicationAdminContinuous.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = ['hospitalization_id', 'admin_dttm', 'med_name', 'med_category', 'med_dose', 'med_dose_unit'],\n",
    "    filters = {\n",
    "        'med_category': ['cisatracurium', 'vecuronium', 'rocuronium']\n",
    "    }\n",
    ")\n",
    "\n",
    "nmb_df = nmb.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3ce90",
   "metadata": {},
   "source": [
    "## Patient & Hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed24080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import Patient, Hospitalization\n",
    "pt = Patient.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = ['patient_id', 'death_dttm'],\n",
    "    )\n",
    "pt_df = pt.df\n",
    "\n",
    "hosp = Hospitalization.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = ['patient_id', 'hospitalization_id', 'discharge_dttm', 'discharge_category', 'age_at_admission'],\n",
    "    )\n",
    "apply_outlier_handling(hosp, outlier_config_path = 'config/outlier_config.yaml')\n",
    "hosp_df = hosp.df\n",
    "\n",
    "q = \"\"\"\n",
    "FROM hosp_df\n",
    "INNER JOIN cohort_imv_streaks_f USING (hospitalization_id)\n",
    "SELECT DISTINCT patient_id, hospitalization_id\n",
    "\"\"\"\n",
    "pt_to_hosp_id_mapper = duckdb.sql(q).df()\n",
    "\n",
    "cohort_pt_ids = pt_to_hosp_id_mapper['patient_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212d38a",
   "metadata": {},
   "source": [
    "# SBT outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627fa01",
   "metadata": {},
   "source": [
    "## Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_path = co.data_directory + '/clif_vitals.parquet'\n",
    "q = f\"\"\"\n",
    "-- find the latest recorded vital for each hospitalization\n",
    "FROM '{vitals_path}'\n",
    "SELECT hospitalization_id\n",
    "    , MAX(recorded_dttm) AS recorded_dttm\n",
    "GROUP BY hospitalization_id\n",
    "\"\"\"\n",
    "last_vitals_df = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0cf2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import Vitals\n",
    "vitals = Vitals.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = ['hospitalization_id', 'recorded_dttm', 'vital_category', 'vital_value'],\n",
    "    filters = {\n",
    "        'vital_category': [\n",
    "            'weight_kg' # 'spo2', , 'respiratory_rate', 'heart_rate'\n",
    "            ],\n",
    "        'hospitalization_id': cohort_hosp_ids\n",
    "    }\n",
    "    )\n",
    "apply_outlier_handling(vitals, outlier_config_path = 'config/outlier_config.yaml')\n",
    "vitals_df = vitals.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d46342",
   "metadata": {},
   "source": [
    "## Code status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import CodeStatus\n",
    "cs = CodeStatus.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = ['patient_id', 'start_dttm', 'code_status_category'],\n",
    "    filters = {\n",
    "        'patient_id': cohort_pt_ids\n",
    "    }\n",
    "    )\n",
    "cs_df = cs.df\n",
    "q = \"\"\"\n",
    "FROM cs_df\n",
    "LEFT JOIN pt_to_hosp_id_mapper USING (patient_id)\n",
    "SELECT hospitalization_id, start_dttm, code_status_category\n",
    "\"\"\"\n",
    "cs_df = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce5c10",
   "metadata": {},
   "source": [
    "## Resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbt_outcomes = run_query_from_file('code/sbt.sql').df()\n",
    "# assert len(sbt_outcomes_f) == len(resp_p), 'length altered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## QA\n",
    "q = \"\"\"\n",
    "-- look for represenative examples to eyeball\n",
    "FROM sbt_outcomes\n",
    "SELECT hospitalization_id\n",
    "    , MAX(_trach_1st) AS _trach_1st\n",
    "    , MAX(_fail_extub) AS _fail_extub\n",
    "    , COUNT(*) AS _n\n",
    "GROUP BY hospitalization_id\n",
    "HAVING _trach_1st = 1 AND _fail_extub = 1 AND _N > 100\n",
    "ORDER BY _n\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51217756",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbt_outcomes['_dh'] = sbt_outcomes['event_dttm'].dt.floor('h', ambiguous='NaT')\n",
    "q = \"\"\"\n",
    "FROM sbt_outcomes\n",
    "SELECT hospitalization_id, _dh\n",
    "    -- , _nth_day\n",
    "    , sbt_done: COALESCE(MAX(sbt_done), 0)\n",
    "    -- , _extub_1st: COALESCE(MAX(_extub_1st), 0)\n",
    "    , success_extub: COALESCE(MAX(_success_extub), 0)\n",
    "    , trach_1st: COALESCE(MAX(_trach_1st), 0)\n",
    "GROUP BY hospitalization_id, _dh\n",
    "ORDER BY hospitalization_id, _dh\n",
    "\"\"\"\n",
    "sbt_outcomes_hrly = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f85f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_hrly_grids_f\n",
    "LEFT JOIN sbt_outcomes_hrly USING (hospitalization_id, _dh)\n",
    "SELECT *\n",
    "ORDER BY hospitalization_id, _dh\n",
    "\"\"\"\n",
    "cohort_sbt_outcomes_hrly = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5db67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_sbt_outcomes_hrly\n",
    "SELECT hospitalization_id, _nth_day\n",
    "    , sbt_done: COALESCE(MAX(sbt_done), 0)\n",
    "    , success_extub: COALESCE(MAX(success_extub), 0)\n",
    "    , trach_1st: COALESCE(MAX(trach_1st), 0)\n",
    "    , n_hrs: COUNT(*)\n",
    "GROUP BY hospitalization_id, _nth_day\n",
    "ORDER BY hospitalization_id, _nth_day\n",
    "\"\"\"\n",
    "cohort_sbt_outcomes_daily = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae812021",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_sbt_outcomes_daily\n",
    "SELECT\n",
    "    hospitalization_id\n",
    "    , sbt_done: COALESCE(MAX(sbt_done), 0)\n",
    "    , success_extub: COALESCE(MAX(success_extub), 0)\n",
    "GROUP BY hospitalization_id\n",
    "\"\"\"\n",
    "cohort_sbt_outcomes_by_pt = duckdb.sql(q).df()\n",
    "print(f\"success_extub rate: {cohort_sbt_outcomes_by_pt['success_extub'].mean()}\")\n",
    "print(f\"sbt_done rate per day: {cohort_sbt_outcomes_daily['sbt_done'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba1324",
   "metadata": {},
   "source": [
    "### Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbt_outcomes_f_w_ids = add_day_shift_id(sbt_outcomes_f)\n",
    "# assert len(sbt_outcomes_f_w_ids) == len(sbt_outcomes_f), 'length altered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a14ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = \"\"\"\n",
    "# WITH agg as (\n",
    "#     FROM sbt_outcomes_f_w_ids\n",
    "#     SELECT hospitalization_id\n",
    "#         , _nth_day\n",
    "#         , sbt_done: COALESCE(MAX(sbt_done), 0)\n",
    "#         , _extub_1st: COALESCE(MAX(_extub_1st), 0)\n",
    "#         , success_extub: COALESCE(MAX(_success_extub), 0)\n",
    "#         , _intub: COALESCE(MAX(_intub), 0)\n",
    "#         , _trach_1st: COALESCE(MAX(_trach_1st), 0)\n",
    "#         , _fail_extub: COALESCE(MAX(_fail_extub), 0)\n",
    "#         , _withdrawl_lst: COALESCE(MAX(_withdrawl_lst), 0)\n",
    "#         , _death_after_extub_wo_reintub: COALESCE(MAX(_death_after_extub_wo_reintub), 0)\n",
    "#         , discharge: ANY_VALUE(discharge_category)\n",
    "#         , code_status: ANY_VALUE(code_status_category ORDER BY cs_start_dttm DESC)\n",
    "\n",
    "#     --WHERE hospitalization_id in ('20001361', '20004088', '20005024')\n",
    "#     GROUP BY hospitalization_id, _nth_day\n",
    "# )\n",
    "# , aug as (\n",
    "#     FROM agg\n",
    "#     SELECT *\n",
    "#         , _exit_sum: success_extub + _trach_1st + _fail_extub + _withdrawl_lst + _death_after_extub_wo_reintub\n",
    "#         , _exit: _exit_sum::BOOL::INT\n",
    "# )\n",
    "# SELECT *\n",
    "# FROM aug\n",
    "# --WHERE hospitalization_id IN ('20001361', '20004088', '20005024', '20006409', '21341369', '20134240', '20008807', '20014600')\n",
    "# ORDER BY hospitalization_id, _nth_day\n",
    "# \"\"\"\n",
    "# resp_traj_by_days = duckdb.sql(q).df()\n",
    "# # resp_traj_by_days.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0986c2d8",
   "metadata": {},
   "source": [
    "# Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbaf14a",
   "metadata": {},
   "source": [
    "## pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import Labs\n",
    "labs = Labs.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = ['hospitalization_id', 'lab_order_dttm', 'lab_result_dttm', 'lab_category', 'lab_value_numeric'],\n",
    "    filters = {\n",
    "        'hospitalization_id': cohort_hosp_ids,\n",
    "        'lab_category': ['ph_arterial', 'ph_venous']\n",
    "    }\n",
    "    )\n",
    "apply_outlier_handling(labs, outlier_config_path = 'config/outlier_config.yaml')\n",
    "labs_df = labs.df\n",
    "\n",
    "q = \"\"\"\n",
    "PIVOT_WIDER labs_df\n",
    "ON lab_category\n",
    "USING MAX(lab_value_numeric)\n",
    "\"\"\"\n",
    "labs_w = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a732f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_shift_change_grids g\n",
    "ASOF LEFT JOIN labs_w l ON\n",
    "    g.hospitalization_id = l.hospitalization_id \n",
    "    AND l.lab_order_dttm <= g.event_dttm\n",
    "SELECT g.*\n",
    "    , l.lab_order_dttm\n",
    "    , l.lab_result_dttm\n",
    "    , l.ph_arterial\n",
    "    , l.ph_venous -- change it to ph_venous: NULL if ph_venous is not available\n",
    "    , ph: COALESCE(ph_arterial, ph_venous + 0.05)\n",
    "    , _time_diff: g.event_dttm - l.lab_order_dttm\n",
    "    , _within_12_hours: CASE WHEN _time_diff <= INTERVAL '12 hour' THEN 1 ELSE 0 END\n",
    "    , ph_level: CASE \n",
    "        WHEN _within_12_hours = 0 THEN 'missing'\n",
    "        WHEN ph < 7.20 THEN 'ph_lt72'\n",
    "        WHEN ph >= 7.20 AND ph < 7.30 THEN 'ph_72_73'\n",
    "        WHEN ph >= 7.30 AND ph < 7.40 THEN 'ph_73_74'\n",
    "        WHEN ph >= 7.40 AND ph < 7.45 THEN 'ph_74_745'\n",
    "        WHEN ph >= 7.45 THEN 'ph_ge745'\n",
    "        ELSE 'missing'\n",
    "    END\n",
    "ORDER BY g.hospitalization_id, g.event_dttm\n",
    "\"\"\"\n",
    "ph_df = duckdb.sql(q).df()\n",
    "assert len(ph_df) == len(cohort_shift_change_grids), 'length altered'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e58b8",
   "metadata": {},
   "source": [
    "## P/F ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba73323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import Labs\n",
    "po2 = Labs.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = ['hospitalization_id', 'lab_order_dttm', 'lab_result_dttm', 'lab_category', 'lab_value_numeric'],\n",
    "    filters = {\n",
    "        'hospitalization_id': cohort_hosp_ids,\n",
    "        'lab_category': ['po2_arterial']\n",
    "    }\n",
    "    )\n",
    "apply_outlier_handling(po2, outlier_config_path = 'config/outlier_config.yaml')\n",
    "po2_df = po2.df\n",
    "\n",
    "q = \"\"\"\n",
    "PIVOT_WIDER po2_df\n",
    "ON lab_category\n",
    "USING MAX(lab_value_numeric)\n",
    "\"\"\"\n",
    "po2_w = duckdb.sql(q).df()\n",
    "# po2_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_shift_change_grids g\n",
    "ASOF LEFT JOIN resp_p r ON\n",
    "    g.hospitalization_id = r.hospitalization_id \n",
    "    AND r.recorded_dttm <= g.event_dttm\n",
    "ASOF LEFT JOIN po2_w p ON\n",
    "    g.hospitalization_id = p.hospitalization_id \n",
    "    AND p.lab_order_dttm <= g.event_dttm\n",
    "SELECT g.*\n",
    "    , fio2_dttm: r.recorded_dttm\n",
    "    , fio2_set: r.fio2_set\n",
    "    , po2_dttm: p.lab_order_dttm\n",
    "    , po2_arterial: p.po2_arterial\n",
    "    , pf: po2_arterial / fio2_set\n",
    "    , pf_level: CASE\n",
    "        WHEN pf is NULL THEN 'missing'\n",
    "        WHEN pf < 100 THEN 'pf_lt100'\n",
    "        WHEN pf >= 100 AND pf < 200 THEN 'pf_100_200'\n",
    "        WHEN pf >= 200 AND pf < 300 THEN 'pf_200_300'\n",
    "        WHEN pf >= 300 THEN 'pf_ge300'\n",
    "        ELSE 'missing'\n",
    "    END\n",
    "ORDER BY g.hospitalization_id, g.event_dttm\n",
    "\"\"\"\n",
    "pf_df = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58711bdd",
   "metadata": {},
   "source": [
    "## Vasopressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f40552",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_veso = MedicationAdminContinuous.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = [\n",
    "        'hospitalization_id', 'admin_dttm', 'med_name', 'med_category', 'med_dose', 'med_dose_unit',\n",
    "        'mar_action_name', 'mar_action_category'\n",
    "        ],\n",
    "    filters = {\n",
    "        'med_category': ['norepinephrine', 'epinephrine', 'phenylephrine', 'dopamine', 'vasopressin', 'angiotensin'], \n",
    "        'hospitalization_id': cohort_hosp_ids\n",
    "    }\n",
    "    )\n",
    "\n",
    "cont_veso_preferred_units = {\n",
    "    'dopamine': 'mcg/kg/min',\n",
    "    # 'dobutamine': 'mcg/kg/min',\n",
    "    'norepinephrine': 'mcg/kg/min',\n",
    "    'epinephrine': 'mcg/kg/min',\n",
    "    'phenylephrine': 'mcg/kg/min',\n",
    "    'angiotensin': 'mcg/kg/min',\n",
    "    'vasopressin': 'u/min',\n",
    "    # 'milrinone': 'mcg/kg/min',\n",
    "    }\n",
    "\n",
    "cont_veso_deduped = remove_meds_duplicates(cont_veso.df)\n",
    "n_removed = len(cont_veso.df) - len(cont_veso_deduped)\n",
    "print(f\"Removed {n_removed} ({n_removed / len(cont_veso.df):.2%}) duplicates by MAR action\")\n",
    "\n",
    "cont_veso_converted, cont_veso_convert_summary = convert_dose_units_by_med_category(\n",
    "    cont_veso_deduped,\n",
    "    vitals_df = vitals_df,\n",
    "    preferred_units = cont_veso_preferred_units,\n",
    "    override = True\n",
    ")\n",
    "\n",
    "cont_veso_converted.rename(columns={\n",
    "    'med_dose': 'med_dose_original', \n",
    "    'med_dose_unit': 'med_dose_unit_original', \n",
    "    'med_dose_converted': 'med_dose', \n",
    "    'med_dose_unit_converted': 'med_dose_unit'\n",
    "    }, inplace=True)\n",
    "\n",
    "cont_veso.df = cont_veso_converted\n",
    "apply_outlier_handling(cont_veso, outlier_config_path = 'config/outlier_config.yaml')\n",
    "cont_veso_converted = cont_veso.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_shift_change_grids g\n",
    "ASOF LEFT JOIN (SELECT * FROM cont_veso_converted WHERE med_category = 'dopamine') m1 ON\n",
    "    g.hospitalization_id = m1.hospitalization_id \n",
    "    AND m1.admin_dttm <= g.event_dttm\n",
    "ASOF LEFT JOIN (SELECT * FROM cont_veso_converted WHERE med_category = 'norepinephrine') m2 ON\n",
    "    g.hospitalization_id = m2.hospitalization_id \n",
    "    AND m2.admin_dttm <= g.event_dttm\n",
    "ASOF LEFT JOIN (SELECT * FROM cont_veso_converted WHERE med_category = 'epinephrine') m3 ON\n",
    "    g.hospitalization_id = m3.hospitalization_id \n",
    "    AND m3.admin_dttm <= g.event_dttm\n",
    "ASOF LEFT JOIN (SELECT * FROM cont_veso_converted WHERE med_category = 'phenylephrine') m4 ON\n",
    "    g.hospitalization_id = m4.hospitalization_id \n",
    "    AND m4.admin_dttm <= g.event_dttm\n",
    "ASOF LEFT JOIN (SELECT * FROM cont_veso_converted WHERE med_category = 'angiotensin') m5 ON\n",
    "    g.hospitalization_id = m5.hospitalization_id \n",
    "    AND m5.admin_dttm <= g.event_dttm\n",
    "ASOF LEFT JOIN (SELECT * FROM cont_veso_converted WHERE med_category = 'vasopressin') m6 ON\n",
    "    g.hospitalization_id = m6.hospitalization_id \n",
    "    AND m6.admin_dttm <= g.event_dttm\n",
    "SELECT g.*\n",
    "    , dopamine: COALESCE(m1.med_dose, 0)\n",
    "    , norepinephrine: COALESCE(m2.med_dose, 0)\n",
    "    , epinephrine: COALESCE(m3.med_dose, 0)\n",
    "    , phenylephrine: COALESCE(m4.med_dose, 0)\n",
    "    , angiotensin: COALESCE(m5.med_dose, 0)\n",
    "    , vasopressin: COALESCE(m6.med_dose, 0)\n",
    "    , _nee: norepinephrine \n",
    "        + epinephrine \n",
    "        + phenylephrine / 10.0 \n",
    "        + dopamine / 100.0 \n",
    "        + vasopressin * 2.5 \n",
    "        + angiotensin * 10\n",
    "ORDER BY g.hospitalization_id, g.event_dttm\n",
    "\"\"\"\n",
    "vaso_df = duckdb.sql(q).df()\n",
    "assert len(ph_df) == len(cohort_shift_change_grids), 'length altered'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85827da7",
   "metadata": {},
   "source": [
    "## Merge covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_shift_change_grids g\n",
    "LEFT JOIN ph_df ph USING (hospitalization_id, event_dttm)\n",
    "LEFT JOIN pf_df pf USING (hospitalization_id, event_dttm)\n",
    "LEFT JOIN vaso_df v USING (hospitalization_id, event_dttm)\n",
    "SELECT g.*\n",
    "    , ph.ph_level\n",
    "    , ph.ph\n",
    "    , pf.pf_level\n",
    "    , pf.pf\n",
    "    , v._nee\n",
    "ORDER BY hospitalization_id, event_dttm\n",
    "\"\"\"\n",
    "covs = duckdb.sql(q).df()\n",
    "\n",
    "q = \"\"\"\n",
    "FROM covs\n",
    "SELECT hospitalization_id\n",
    "    --, event_dttm: MIN(event_dttm)\n",
    "    , _nth_day\n",
    "    , ph_level_7am: COALESCE(ANY_VALUE(CASE WHEN _hr = 7 THEN ph_level END), 'missing')\n",
    "    , ph_level_7pm: COALESCE(ANY_VALUE(CASE WHEN _hr = 19 THEN ph_level END), 'missing')\n",
    "    , pf_level_7am: COALESCE(ANY_VALUE(CASE WHEN _hr = 7 THEN pf_level END), 'missing')\n",
    "    , pf_level_7pm: COALESCE(ANY_VALUE(CASE WHEN _hr = 19 THEN pf_level END), 'missing')\n",
    "    , nee_7am: COALESCE(ANY_VALUE(CASE WHEN _hr = 7 THEN _nee END), 0)\n",
    "    , nee_7pm: COALESCE(ANY_VALUE(CASE WHEN _hr = 19 THEN _nee END), 0)\n",
    "    , _ph_7am: ANY_VALUE(CASE WHEN _hr = 7 THEN ph END)\n",
    "    , _ph_7pm: ANY_VALUE(CASE WHEN _hr = 19 THEN ph END)\n",
    "    , _pf_7am: ANY_VALUE(CASE WHEN _hr = 7 THEN pf END)\n",
    "    , _pf_7pm: ANY_VALUE(CASE WHEN _hr = 19 THEN pf END)\n",
    "GROUP BY hospitalization_id, _nth_day\n",
    "ORDER BY hospitalization_id, _nth_day\n",
    "\"\"\"\n",
    "covs_daily = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc741e6f",
   "metadata": {},
   "source": [
    "# Sedation dose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fe254",
   "metadata": {},
   "source": [
    "### Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134523fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sed = MedicationAdminContinuous.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = [\n",
    "        'hospitalization_id', 'admin_dttm', 'med_name', 'med_category', 'med_dose', 'med_dose_unit',\n",
    "        'mar_action_name', 'mar_action_category'\n",
    "        ],\n",
    "    filters = {\n",
    "        'med_category': ['hydromorphone', 'fentanyl', 'lorazepam', 'midazolam', 'propofol'], \n",
    "        'hospitalization_id': cohort_hosp_ids\n",
    "    }\n",
    "    )\n",
    "\n",
    "# apply_outlier_handling(cont_sed, outlier_config_path = 'config/outlier_config.yaml')\n",
    "cont_sed_preferred_units = {\n",
    "    'propofol': 'mg/min',\n",
    "    #'dexmedetomidine': 'mcg/min',\n",
    "    #'ketamine': 'mg/min',\n",
    "    'midazolam': 'mg/min',\n",
    "    'fentanyl': 'mcg/min',\n",
    "    'hydromorphone': 'mg/min',\n",
    "    #'morphine': 'mg/min',\n",
    "    #'remifentanil': 'mcg/min',\n",
    "    #'pentobarbital': 'mg/min',\n",
    "    'lorazepam': 'mg/min'\n",
    "    }\n",
    "\n",
    "cont_sed_deduped = remove_meds_duplicates(cont_sed.df)\n",
    "n_removed = len(cont_sed.df) - len(cont_sed_deduped)\n",
    "print(f\"Removed {n_removed} ({n_removed / len(cont_sed.df):.2%}) duplicates by MAR action\")\n",
    "\n",
    "cont_sed_converted, cont_sed_convert_summary = convert_dose_units_by_med_category(\n",
    "    cont_sed_deduped,\n",
    "    vitals_df = vitals_df,\n",
    "    preferred_units = cont_sed_preferred_units,\n",
    "    override = True\n",
    ")\n",
    "print(f\"{len(cont_sed_converted)} rows in intm_sed_converted\")\n",
    "cont_sed_converted.rename(columns={\n",
    "    'med_dose': 'med_dose_original', \n",
    "    'med_dose_unit': 'med_dose_unit_original', \n",
    "    'med_dose_converted': 'med_dose', \n",
    "    'med_dose_unit_converted': 'med_dose_unit'\n",
    "    }, inplace=True)\n",
    "\n",
    "cont_sed.df = cont_sed_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_outlier_handling(cont_sed, outlier_config_path = 'config/outlier_config.yaml')\n",
    "print(f\"{len(cont_sed_converted)} rows in intm_sed_converted\")\n",
    "cont_sed_converted = cont_sed.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4712ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "-- converting to wide format\n",
    "WITH t1 AS (\n",
    "    SELECT hospitalization_id\n",
    "        , admin_dttm as event_dttm\n",
    "        , med_category_unit: med_category || '_' || REPLACE(med_dose_unit, '/', '_') || '_cont'\n",
    "        , med_dose\n",
    "    FROM cont_sed_converted\n",
    ")\n",
    ", t2 AS (\n",
    "    PIVOT_WIDER t1\n",
    "    ON med_category_unit\n",
    "    USING FIRST(med_dose)\n",
    ")\n",
    "SELECT *\n",
    "FROM t2\n",
    "ORDER BY hospitalization_id, event_dttm\n",
    "\"\"\"\n",
    "cont_sed_w = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed102a",
   "metadata": {},
   "source": [
    "## Intermittent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy import MedicationAdminIntermittent\n",
    "\n",
    "intm_sed = MedicationAdminIntermittent.from_file(\n",
    "    config_path = 'config/config.json',\n",
    "    columns = [\n",
    "        'hospitalization_id', 'admin_dttm', 'med_name', 'med_category', 'med_dose', 'med_dose_unit',\n",
    "        'mar_action_name', 'mar_action_category'\n",
    "        ],\n",
    "    filters = {\n",
    "        'med_category': ['hydromorphone', 'fentanyl', 'lorazepam', 'midazolam', 'propofol'], \n",
    "        'hospitalization_id': cohort_hosp_ids\n",
    "    }\n",
    "    )\n",
    "\n",
    "intm_sed_preferred_units = {\n",
    "    'propofol': 'mg',\n",
    "    #'dexmedetomidine': 'mcg/min',\n",
    "    #'ketamine': 'mg/min',\n",
    "    'midazolam': 'mg',\n",
    "    'fentanyl': 'mcg',\n",
    "    'hydromorphone': 'mg',\n",
    "    #'morphine': 'mg/min',\n",
    "    #'remifentanil': 'mcg/min',\n",
    "    #'pentobarbital': 'mg/min',\n",
    "    'lorazepam': 'mg'\n",
    "    }\n",
    "\n",
    "intm_sed_deduped = remove_meds_duplicates(intm_sed.df)\n",
    "n_removed = len(intm_sed.df) - len(intm_sed_deduped)\n",
    "print(f\"Removed {n_removed} ({n_removed / len(intm_sed.df):.2%}) duplicates by MAR action\")\n",
    "\n",
    "intm_sed_converted, intm_sed_convert_summary = convert_dose_units_by_med_category(\n",
    "    intm_sed_deduped,\n",
    "    vitals_df = vitals_df,\n",
    "    preferred_units = intm_sed_preferred_units,\n",
    "    override = True\n",
    ")\n",
    "print(f\"{len(cont_sed_converted)} rows in intm_sed_converted\")\n",
    "intm_sed_converted.rename(columns={\n",
    "    'med_dose': 'med_dose_original', \n",
    "    'med_dose_unit': 'med_dose_unit_original', \n",
    "    'med_dose_converted': 'med_dose', \n",
    "    'med_dose_unit_converted': 'med_dose_unit'\n",
    "    }, inplace=True)\n",
    "intm_sed.df = intm_sed_converted\n",
    "\n",
    "apply_outlier_handling(intm_sed, outlier_config_path = 'config/outlier_config.yaml')\n",
    "print(f\"{len(intm_sed_converted)} rows in intm_sed_converted\")\n",
    "intm_sed_converted = intm_sed.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9dfdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "-- converting to wide format\n",
    "WITH t1 AS (\n",
    "    SELECT hospitalization_id\n",
    "        , admin_dttm as event_dttm\n",
    "        , med_category_unit: med_category || '_' || REPLACE(med_dose_unit, '/', '_') || '_intm'\n",
    "        , med_dose: CASE WHEN mar_action_category = 'not_given' THEN 0 ELSE med_dose END\n",
    "    FROM intm_sed_converted\n",
    ")\n",
    ", t2 AS (\n",
    "    PIVOT_WIDER t1\n",
    "    ON med_category_unit\n",
    "    USING FIRST(med_dose)\n",
    ")\n",
    "SELECT *\n",
    "FROM t2\n",
    "ORDER BY hospitalization_id, event_dttm\n",
    "\"\"\"\n",
    "intm_sed_w = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e320d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "-- create the hourly grid for the wide sedation table\n",
    "FROM cohort_hrly_grids_f g\n",
    "FULL JOIN cont_sed_w m USING (hospitalization_id, event_dttm)\n",
    "ORDER BY hospitalization_id, event_dttm\n",
    "\"\"\"\n",
    "# wide table with hourly grids inserted\n",
    "cont_sed_wg = duckdb.sql(q).df()\n",
    "cont_sed_wg['_dh'] = cont_sed_wg['event_dttm'].dt.floor('h', ambiguous='NaT')\n",
    "cont_sed_wg['_hr'] = cont_sed_wg['event_dttm'].dt.hour\n",
    "print(len(cont_sed_wg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "-- create the hourly grid for the wide sedation table\n",
    "FROM cohort_hrly_grids_f g\n",
    "FULL JOIN intm_sed_w m USING (hospitalization_id, event_dttm)\n",
    "ORDER BY hospitalization_id, event_dttm\n",
    "\"\"\"\n",
    "intm_sed_wg = duckdb.sql(q).df()\n",
    "intm_sed_wg['_dh'] = intm_sed_wg['event_dttm'].dt.floor('h', ambiguous='NaT')\n",
    "intm_sed_wg['_hr'] = intm_sed_wg['event_dttm'].dt.hour\n",
    "print(len(intm_sed_wg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784be320",
   "metadata": {},
   "source": [
    "## Hrly sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sed_dose_by_hr = run_query_from_file('code/cont_sed_dose_by_hr.sql').df()\n",
    "print(len(cont_sed_dose_by_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44750bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM intm_sed_wg\n",
    "SELECT hospitalization_id, _dh\n",
    "    , SUM(COALESCE(COLUMNS('_intm'), 0))\n",
    "GROUP BY hospitalization_id, _dh\n",
    "ORDER BY hospitalization_id, _dh\n",
    "\"\"\"\n",
    "intm_sed_dose_by_hr = duckdb.sql(q).df()\n",
    "print(len(intm_sed_dose_by_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb43887",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "-- join the cont and intm hourly cumm dose table\n",
    "WITH t1 as (\n",
    "    FROM cohort_hrly_grids_f g\n",
    "    LEFT JOIN intm_sed_dose_by_hr i USING (hospitalization_id, _dh)\n",
    "    LEFT JOIN cont_sed_dose_by_hr c USING (hospitalization_id, _dh)\n",
    "    SELECT *\n",
    ")\n",
    ", t2 as (\n",
    "    SELECT *\n",
    "        , fentanyl_mcg_total: fentanyl_mcg_intm + fentanyl_mcg_min_cont\n",
    "        , hydromorphone_mg_total: hydromorphone_mg_intm + hydromorphone_mg_min_cont\n",
    "        , lorazepam_mg_total: lorazepam_mg_intm + lorazepam_mg_min_cont\n",
    "        , midazolam_mg_total: midazolam_mg_intm + midazolam_mg_min_cont\n",
    "        , propofol_mg_total: propofol_mg_intm + propofol_mg_min_cont\n",
    "        , _midazolam_eq_mg_total: lorazepam_mg_total * 2 + midazolam_mg_total\n",
    "        , _fentanyl_eq_mcg_total: hydromorphone_mg_total * 50 + fentanyl_mcg_total\n",
    "    FROM t1\n",
    ")\n",
    "SELECT *\n",
    "FROM t2\n",
    "ORDER BY hospitalization_id, _dh\n",
    "\"\"\"\n",
    "sed_dose_by_hr = duckdb.sql(q).df()\n",
    "#assert len(sed_dose_by_hr) == len(cont_sed_dose_by_hr), 'length altered for cont sed'\n",
    "#assert len(sed_dose_by_hr) == len(intm_sed_dose_by_hr), 'length altered for intm sed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab8588",
   "metadata": {},
   "source": [
    "## By shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e80592",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM sed_dose_by_hr\n",
    "SELECT _shift\n",
    "    , propofol_mg: AVG(propofol_mg_total)\n",
    "    , _fentanyl_eq_mcg: AVG(_fentanyl_eq_mcg_total)\n",
    "    , _midazolam_eq_mg: AVG(_midazolam_eq_mg_total)\n",
    "GROUP BY _shift\n",
    "ORDER BY _shift\n",
    "\"\"\"\n",
    "sed_dose_by_shift = duckdb.sql(q).df()\n",
    "\n",
    "# sed_dose_by_shift.to_csv(f'output/final/{SITE_NAME}_sed_dose_by_shift_{CURRENT_TIME_STR}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Columns to test, keep as raw *_total column names for clarity and consistency\n",
    "test_cols = [\n",
    "    \"propofol_mg_total\",\n",
    "    \"_fentanyl_eq_mcg_total\",\n",
    "    \"_midazolam_eq_mg_total\",\n",
    "]\n",
    "\n",
    "# Get the dose data for each shift\n",
    "shift_day = sed_dose_by_hr[sed_dose_by_hr[\"_shift\"] == \"day\"]\n",
    "shift_night = sed_dose_by_hr[sed_dose_by_hr[\"_shift\"] == \"night\"]\n",
    "\n",
    "# Perform t-tests and store p-values using *_total column names\n",
    "t_pvals = {}\n",
    "for col in test_cols:\n",
    "    tstat, pval = stats.ttest_ind(\n",
    "        shift_day[col],\n",
    "        shift_night[col],\n",
    "        nan_policy=\"omit\", equal_var=False\n",
    "    )\n",
    "    t_pvals[col] = pval\n",
    "\n",
    "# Prepare summary table: output columns match sed_dose_by_shift, but we keep *_total column names for ttest row\n",
    "out_df = sed_dose_by_shift.rename(columns={\n",
    "    \"propofol_mg\": \"propofol_mg_total\",\n",
    "    \"_fentanyl_eq_mcg\": \"_fentanyl_eq_mcg_total\",\n",
    "    \"_midazolam_eq_mg\": \"_midazolam_eq_mg_total\",\n",
    "    \"_shift\": \"shift\"\n",
    "}).loc[:, [\"shift\", \"propofol_mg_total\", \"_fentanyl_eq_mcg_total\", \"_midazolam_eq_mg_total\"]]\n",
    "\n",
    "# Add a ttest_pval row, matching columns present in out_df\n",
    "pval_row = pd.Series({\n",
    "    \"shift\": \"ttest_pval\",\n",
    "    \"propofol_mg_total\": t_pvals[\"propofol_mg_total\"],\n",
    "    \"_fentanyl_eq_mcg_total\": t_pvals[\"_fentanyl_eq_mcg_total\"],\n",
    "    \"_midazolam_eq_mg_total\": t_pvals[\"_midazolam_eq_mg_total\"],\n",
    "})\n",
    "\n",
    "out_df = pd.concat([out_df, pd.DataFrame([pval_row])], ignore_index=True)\n",
    "\n",
    "# Save\n",
    "out_df.to_csv(f'output/final/{SITE_NAME}_sed_dose_by_shift_with_ttest_{CURRENT_TIME_STR}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e2841",
   "metadata": {},
   "source": [
    "## By hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM sed_dose_by_hr\n",
    "SELECT _hr\n",
    "    , propofol_mg: AVG(propofol_mg_total)\n",
    "    , _fentanyl_eq_mcg: AVG(_fentanyl_eq_mcg_total)\n",
    "    , _midazolam_eq_mg: AVG(_midazolam_eq_mg_total)\n",
    "GROUP BY _hr\n",
    "ORDER BY _hr\n",
    "\"\"\"\n",
    "sed_dose_by_hr_of_day = duckdb.sql(q).df()\n",
    "\n",
    "sed_dose_by_hr_of_day.to_csv(f'output/final/{SITE_NAME}_sed_dose_by_hr_of_day_{CURRENT_TIME_STR}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff00f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract variables for plotting\n",
    "hours = sed_dose_by_hr_of_day['_hr']\n",
    "propofol = sed_dose_by_hr_of_day['propofol_mg']\n",
    "fentanyl_eq = sed_dose_by_hr_of_day['_fentanyl_eq_mcg']\n",
    "midazolam_eq = sed_dose_by_hr_of_day['_midazolam_eq_mg']\n",
    "\n",
    "# Reorder so that x-axis goes from 7,8,...,23,0,1,...,6\n",
    "desired_order = list(range(7, 24)) + list(range(0, 7))\n",
    "hours_ordered = []\n",
    "propofol_ordered = []\n",
    "fentanyl_eq_ordered = []\n",
    "midazolam_eq_ordered = []\n",
    "\n",
    "for h in desired_order:\n",
    "    if h in list(hours):\n",
    "        idx = list(hours).index(h)\n",
    "        hours_ordered.append(hours.iloc[idx])\n",
    "        propofol_ordered.append(propofol.iloc[idx])\n",
    "        fentanyl_eq_ordered.append(fentanyl_eq.iloc[idx])\n",
    "        midazolam_eq_ordered.append(midazolam_eq.iloc[idx])\n",
    "\n",
    "hours_ordered = np.array(hours_ordered)\n",
    "propofol_ordered = np.array(propofol_ordered)\n",
    "fentanyl_eq_ordered = np.array(fentanyl_eq_ordered)\n",
    "midazolam_eq_ordered = np.array(midazolam_eq_ordered)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(13, 12), sharex=True)\n",
    "\n",
    "x = np.arange(len(hours_ordered))\n",
    "bar_width = 0.6\n",
    "\n",
    "# Propofol\n",
    "axs[0].bar(x, propofol_ordered, color='skyblue', width=bar_width)\n",
    "axs[0].set_ylabel('Propofol (mg)')\n",
    "axs[0].set_title('Mean Total Propofol Dose by Hour of Day')\n",
    "axs[0].grid(True, axis='y')\n",
    "\n",
    "# Fentanyl Eq\n",
    "axs[1].bar(x, fentanyl_eq_ordered, color='salmon', width=bar_width)\n",
    "axs[1].set_ylabel('Fentanyl Eq (mcg)')\n",
    "axs[1].set_title('Mean Total Fentanyl Equivalent Dose by Hour of Day')\n",
    "axs[1].grid(True, axis='y')\n",
    "\n",
    "# Midazolam Eq\n",
    "axs[2].bar(x, midazolam_eq_ordered, color='mediumseagreen', width=bar_width)\n",
    "axs[2].set_ylabel('Midazolam Eq (mg)')\n",
    "axs[2].set_title('Mean Total Midazolam Equivalent Dose by Hour of Day')\n",
    "axs[2].set_xlabel('Hour of Day (_hr)')\n",
    "axs[2].grid(True, axis='y')\n",
    "\n",
    "# Add cutoff lines at _hr=7 and _hr=19 to each axis (find their positions in the reordered hours)\n",
    "for ax in axs:\n",
    "    for cutoff in [19]:\n",
    "        if cutoff in hours_ordered:\n",
    "            cutoff_pos = np.where(hours_ordered == cutoff)[0][0]\n",
    "            ax.axvline(cutoff_pos - 0.5, color='red', linestyle='--', linewidth=2, alpha=0.8)\n",
    "        else:\n",
    "            insert_pos = np.searchsorted(hours_ordered, cutoff)\n",
    "            ax.axvline(insert_pos - 0.5, color='red', linestyle='--', linewidth=2, alpha=0.8)\n",
    "\n",
    "plt.xticks(x, hours_ordered.astype(int))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a title with the site_name variable\n",
    "plt.suptitle(f'Cumulative Sedative Doses by Hour of Day â€” {SITE_NAME}', fontsize=18, y=1.04)\n",
    "# Save the figure to file in output/final/{site_name}_sed_dose_by_hr_of_day_{current time down to sec}\n",
    "os.makedirs('output/final', exist_ok=True)\n",
    "save_path = f'output/final/{SITE_NAME}_sed_dose_by_hr_of_day_{CURRENT_TIME_STR}.png'\n",
    "plt.savefig(save_path, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935ecef",
   "metadata": {},
   "source": [
    "## By day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87900e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "-- Aggregate per hospitalization, day, shift\n",
    "FROM sed_dose_by_hr\n",
    "SELECT\n",
    "    hospitalization_id,\n",
    "    _nth_day,\n",
    "    _shift,\n",
    "    SUM(propofol_mg_total) AS propofol_mg_total,\n",
    "    SUM(_fentanyl_eq_mcg_total) AS fentanyl_eq_mcg_total,\n",
    "    SUM(_midazolam_eq_mg_total) AS midazolam_eq_mg_total\n",
    "GROUP BY hospitalization_id, _nth_day, _shift\n",
    "ORDER BY hospitalization_id, _nth_day, _shift\n",
    "\"\"\"\n",
    "sed_dose_agg = duckdb.sql(q).df()\n",
    "\n",
    "sed_dose_daily = sed_dose_agg.pivot(\n",
    "    index=['hospitalization_id', '_nth_day'],\n",
    "    columns='_shift',\n",
    "    values=['propofol_mg_total', 'fentanyl_eq_mcg_total', 'midazolam_eq_mg_total']\n",
    ").reset_index()\n",
    "\n",
    "# Optionally flatten MultiIndex columns and rename as requested\n",
    "sed_dose_daily.columns = [\n",
    "    'hospitalization_id', '_nth_day',\n",
    "    'propofol_day' if ('propofol_mg_total', 'day') in sed_dose_daily.columns else None,\n",
    "    'propofol_night' if ('propofol_mg_total', 'night') in sed_dose_daily.columns else None,\n",
    "    'fentanyl_eq_day' if ('fentanyl_eq_mcg_total', 'day') in sed_dose_daily.columns else None,\n",
    "    'fentanyl_eq_night' if ('fentanyl_eq_mcg_total', 'night') in sed_dose_daily.columns else None,\n",
    "    'midazolam_eq_day' if ('midazolam_eq_mg_total', 'day') in sed_dose_daily.columns else None,\n",
    "    'midazolam_eq_night' if ('midazolam_eq_mg_total', 'night') in sed_dose_daily.columns else None,\n",
    "]\n",
    "# Remove 'None' columns in case day or night is missing\n",
    "sed_dose_daily = sed_dose_daily.loc[:, [c for c in sed_dose_daily.columns if c is not None]]\n",
    "\n",
    "# For full reproducibility, here is a more rigid column assignment to avoid None if both shifts exist:\n",
    "# sed_dose_wide.columns = [\n",
    "#     'hospitalization_id', '_nth_day',\n",
    "#     'propofol_day', 'propofol_night',\n",
    "#     'fentanyl_eq_day', 'feantanyl_eq_night',\n",
    "#     'midazolam_eq_day', 'midazolam_eq_night'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = \"\"\"\n",
    "# PIVOT_WIDER sed_dose_by_day_shift\n",
    "# ON _shift\n",
    "# USING SUM(propofol_mg_total)\n",
    "# ORDER BY hospitalization_id, _nth_day\n",
    "# \"\"\"\n",
    "# sed_dose_by_day_shift_w = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a4416",
   "metadata": {},
   "source": [
    "# Merge into analytical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe948131",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_sbt_outcomes_daily o\n",
    "LEFT JOIN sed_dose_daily s USING (hospitalization_id, _nth_day)\n",
    "LEFT JOIN covs_daily c USING (hospitalization_id, _nth_day)\n",
    "LEFT JOIN hosp_df h USING (hospitalization_id)\n",
    "SELECT o.hospitalization_id\n",
    "    , o._nth_day\n",
    "    , o.n_hrs\n",
    "    , _sbt_done_today: o.sbt_done\n",
    "    , _success_extub_today: o.success_extub\n",
    "    , sbt_done_next_day: LEAD(o.sbt_done) OVER w\n",
    "    , success_extub_next_day: LEAD(o.success_extub) OVER w\n",
    "    --, o.trach_1st\n",
    "    , _propofol_day: COALESCE(s.propofol_day, 0)\n",
    "    , _propofol_night: COALESCE(s.propofol_night, 0)\n",
    "    , _fentanyl_eq_day: COALESCE(s.fentanyl_eq_day, 0)\n",
    "    , _fentanyl_eq_night: COALESCE(s.fentanyl_eq_night, 0)\n",
    "    , _midazolam_eq_day: COALESCE(s.midazolam_eq_day, 0)\n",
    "    , _midazolam_eq_night: COALESCE(s.midazolam_eq_night, 0)\n",
    "    , propofol_diff: COALESCE(s.propofol_night, 0) - COALESCE(s.propofol_day, 0)\n",
    "    , fentanyl_eq_diff: COALESCE(s.fentanyl_eq_night, 0) - COALESCE(s.fentanyl_eq_day, 0)\n",
    "    , midazolam_eq_diff: COALESCE(s.midazolam_eq_night, 0) - COALESCE(s.midazolam_eq_day, 0)\n",
    "    , COLUMNS('(7am)|(7pm)')\n",
    "    , age: h.age_at_admission\n",
    "WINDOW w AS (PARTITION BY hospitalization_id ORDER BY _nth_day)\n",
    "ORDER BY o.hospitalization_id, o._nth_day\n",
    "\"\"\"\n",
    "cohort_merged = duckdb.sql(q).df()\n",
    "\n",
    "cohort_merged.dropna(subset=['age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f26965",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_merged\n",
    "SELECT *\n",
    "WHERE _nth_day > 0 AND sbt_done_next_day IS NOT NULL AND success_extub_next_day IS NOT NULL\n",
    "\"\"\"\n",
    "cohort_merged_final = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f890b",
   "metadata": {},
   "source": [
    "# Table one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a360a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tableone\n",
    "\n",
    "def gen_and_save_tableone(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper for tableone.TableOne that automatically saves results to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame to create table one from\n",
    "        file_name: Name for the output file (without extension)\n",
    "        **kwargs: All other arguments passed to tableone.TableOne\n",
    "    \n",
    "    Returns:\n",
    "        tableone.TableOne object\n",
    "    \"\"\"\n",
    "    table = tableone.TableOne(**kwargs)\n",
    "    table.to_csv(f'output/final/{SITE_NAME}_{file_name}_{CURRENT_TIME_STR}.csv')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1219881",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "FROM cohort_merged_final\n",
    "SELECT * -- EXCLUDE(hospitalization_id)\n",
    "WHERE _nth_day = 1\n",
    "\"\"\"\n",
    "cohort_merged_for_t1 = duckdb.sql(q).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "236e6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "WITH t1 AS (\n",
    "    FROM cohort_merged_for_t1 g\n",
    "    LEFT JOIN sed_dose_agg s USING (hospitalization_id, _nth_day)\n",
    "    LEFT JOIN hosp_df h USING (hospitalization_id)\n",
    "    SELECT g.hospitalization_id, g._nth_day\n",
    "        , s._shift\n",
    "        , s.propofol_mg_total\n",
    "        , s.fentanyl_eq_mcg_total\n",
    "        , s.midazolam_eq_mg_total\n",
    "        , h.patient_id\n",
    ")\n",
    ", t2 AS (\n",
    "    FROM t1\n",
    "    LEFT JOIN covs c USING (hospitalization_id, _nth_day, _shift)\n",
    "    SELECT *\n",
    ")\n",
    "SELECT *\n",
    "FROM t2\n",
    "ORDER BY hospitalization_id, _nth_day, _shift\n",
    "\"\"\"\n",
    "cohort_merged_for_t1_w_by_shift = duckdb.sql(q).df()\n",
    "assert len(cohort_merged_for_t1) * 2 == len(cohort_merged_for_t1_w_by_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "646ac76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_patients = cohort_merged_for_t1_w_by_shift['patient_id'].nunique()\n",
    "pd.DataFrame({'n_unique_patients': [n_unique_patients]})\\\n",
    "    .to_csv(f'output/final/{SITE_NAME}_cohort_stats_{CURRENT_TIME_STR}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2c95590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Missing</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td>9903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">_sbt_done_today, n (%)</th>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>7746 (78.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2157 (21.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">_success_extub_today, n (%)</th>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>9891 (99.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>12 (0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propofol_diff, mean (SD)</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>-30.1 (655.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fentanyl_eq_diff, mean (SD)</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>-4.5 (399.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midazolam_eq_diff, mean (SD)</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.0 (5.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age, mean (SD)</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>56.9 (17.6)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br />"
      ],
      "text/plain": [
       "                               Missing        Overall\n",
       "n                                                9903\n",
       "_sbt_done_today, n (%)       0            7746 (78.2)\n",
       "                             1            2157 (21.8)\n",
       "_success_extub_today, n (%)  0            9891 (99.9)\n",
       "                             1               12 (0.1)\n",
       "propofol_diff, mean (SD)             0  -30.1 (655.0)\n",
       "fentanyl_eq_diff, mean (SD)          0   -4.5 (399.2)\n",
       "midazolam_eq_diff, mean (SD)         0      0.0 (5.4)\n",
       "age, mean (SD)                       0    56.9 (17.6)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_vars = ['_sbt_done_today', '_success_extub_today']\n",
    "diff_doses = ['propofol_diff', 'fentanyl_eq_diff', 'midazolam_eq_diff']\n",
    "\n",
    "cont_vars = ['age'] + diff_doses\n",
    "cat_vars = outcome_vars\n",
    "\n",
    "gen_and_save_tableone(\n",
    "    file_name='table_one_day_1',\n",
    "    data=cohort_merged_for_t1, \n",
    "    continuous=cont_vars, \n",
    "    categorical=cat_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ebdb2",
   "metadata": {},
   "source": [
    "## day-night comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8aa91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_vars = ['propofol_mg_total', 'fentanyl_eq_mcg_total', 'midazolam_eq_mg_total']\n",
    "\n",
    "cont_vars = sed_vars + ['ph', 'pf','_nee']\n",
    "cat_vars = ['ph_level', 'pf_level']\n",
    "nonnorm_vars = ['ph', 'pf']\n",
    "\n",
    "gen_and_save_tableone(\n",
    "    file_name='table_one_day_1_by_shift',\n",
    "    pval=True,\n",
    "    data=cohort_merged_for_t1_w_by_shift, \n",
    "    continuous=cont_vars, \n",
    "    groupby='_shift',\n",
    "    categorical=cat_vars,\n",
    "    # nonnormal=nonnorm_vars\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31832b23",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define your list of continuous variables as in your earlier code\n",
    "continuous_vars = [\n",
    "    'age', \n",
    "    'propofol_diff', 'fentanyl_eq_diff', 'midazolam_eq_diff',\n",
    "    '_propofol_day', '_propofol_night',\n",
    "    '_fentanyl_eq_day', '_fentanyl_eq_night',\n",
    "    '_midazolam_eq_day', '_midazolam_eq_night',\n",
    "    'nee_7am', 'nee_7pm',\n",
    "    '_ph_7am', '_ph_7pm', '_pf_7am', '_pf_7pm'\n",
    "]\n",
    "\n",
    "# Only select columns that exist in the dataframe (to avoid KeyError)\n",
    "continuous_vars_df = cohort_merged_final[[col for col in continuous_vars if col in cohort_merged_final.columns]]\n",
    "\n",
    "# Compute pairwise Pearson correlations between continuous variables\n",
    "corr_matrix = continuous_vars_df.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"vlag\",\n",
    "    linewidths=.5,\n",
    "    cbar_kws={'label': 'Pearson Correlation'}\n",
    ")\n",
    "plt.title('Pairwise Pearson Correlation Matrix (Continuous Variables)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the correlation matrix to CSV in output/final\n",
    "corr_matrix.to_csv(f\"output/final/{SITE_NAME}_pairwise_corr_matrix_{CURRENT_TIME_STR}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sbt_done_formula = \"\"\"sbt_done_next_day ~ propofol_diff + fentanyl_eq_diff + midazolam_eq_diff +\n",
    "    _propofol_day + _midazolam_eq_day + _fentanyl_eq_day +\n",
    "    ph_level_7am + ph_level_7pm + pf_level_7am + pf_level_7pm + nee_7am + nee_7pm + age\n",
    "\"\"\"\n",
    "\n",
    "# GEE regression\n",
    "gee_model = smf.gee(formula=sbt_done_formula, groups=\"hospitalization_id\", data=cohort_merged_final, family=sm.families.Binomial())\n",
    "gee_result = gee_model.fit()\n",
    "print(gee_result.summary())\n",
    "\n",
    "# Save the summary as CSV for readability\n",
    "summary_df = gee_result.summary().tables[1]\n",
    "# Convert the summary table to DataFrame\n",
    "summary_pd = pd.DataFrame(summary_df.data[1:], columns=summary_df.data[0])\n",
    "summary_pd.to_csv(f\"output/final/{SITE_NAME}_gee_summary_{CURRENT_TIME_STR}.csv\", index=False)\n",
    "\n",
    "# Save covariance matrix of the model\n",
    "cov_matrix = gee_result.cov_params()\n",
    "cov_matrix.to_csv(f\"output/final/{SITE_NAME}_gee_covmat_{CURRENT_TIME_STR}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit regression with clustered standard errors\n",
    "success_extub_formula = \"\"\"success_extub_next_day ~ propofol_diff + fentanyl_eq_diff + midazolam_eq_diff +\n",
    "    _propofol_day + _midazolam_eq_day + _fentanyl_eq_day +\n",
    "    ph_level_7am + ph_level_7pm + pf_level_7am + pf_level_7pm + nee_7am + nee_7pm + age\n",
    "\"\"\"\n",
    "logit_model = smf.logit(formula=success_extub_formula, data=cohort_merged_final)\n",
    "logit_result = logit_model.fit(cov_type='cluster', cov_kwds={'groups': cohort_merged_final['hospitalization_id']})\n",
    "print(logit_result.summary())\n",
    "\n",
    "# Save the summary as CSV for readability\n",
    "summary_df = logit_result.summary().tables[1]\n",
    "# Convert the summary table to DataFrame\n",
    "summary_pd = pd.DataFrame(summary_df.data[1:], columns=summary_df.data[0])\n",
    "summary_pd.to_csv(f\"output/final/{SITE_NAME}_logit_summary_{CURRENT_TIME_STR}.csv\", index=False)\n",
    "\n",
    "# Save covariance matrix of the model\n",
    "cov_matrix = logit_result.cov_params()\n",
    "cov_matrix.to_csv(f\"output/final/{SITE_NAME}_logit_covmat_{CURRENT_TIME_STR}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
