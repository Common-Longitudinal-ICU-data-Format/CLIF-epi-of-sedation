{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db95619c",
   "metadata": {},
   "source": [
    "# Epidemiology of Sedation in Mechanical Ventilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab2ea0",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9757eb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/wliao0504/code/clif'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8108d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "from utils import pyCLIF as pc\n",
    "from utils.waterfall import process_resp_support_waterfall\n",
    "import ipytest\n",
    "import tableone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097baf93",
   "metadata": {},
   "source": [
    "## Cohort Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "325f51b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/wliao0504/code/clif/CLIF-MIMIC/output/rclif-dev-test-copy/clif_adt.parquet\n",
      "Data loaded successfully from /Users/wliao0504/code/clif/CLIF-MIMIC/output/rclif-dev-test-copy/clif_hospitalization.parquet\n"
     ]
    }
   ],
   "source": [
    "adt = pc.load_data(\"clif_adt\")\n",
    "hospitalization = pc.load_data(\"clif_hospitalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459dbf0",
   "metadata": {},
   "source": [
    "### Create ICU-stay level unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a22d7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    stitched_encounters = pc.stitch_encounters(hospitalization, adt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f302c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping table\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT patient_id, hospitalization_id, encounter_block\n",
    "FROM stitched_encounters\n",
    "\"\"\"\n",
    "hosp_to_enc_blk_mapper = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfcfe9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT hospitalization_id\n",
    "    , encounter_block\n",
    "    , date_trunc('hour', in_dttm) as in_date_hr\n",
    "    , 1 as new_icu_stay\n",
    "FROM stitched_encounters\n",
    "WHERE location_category = 'icu'\n",
    "\"\"\"\n",
    "new_icu_start_hours = duckdb.sql(query).to_df()\n",
    "\n",
    "hosp_ids_w_icu_stays = new_icu_start_hours['hospitalization_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b1f5e",
   "metadata": {},
   "source": [
    "### Hour 24 and 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9c711842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = pc.load_data(\n",
    "#     table = \"clif_respiratory_support\",\n",
    "#     filters = {\n",
    "#         \"hospitalization_id\": hosp_ids_w_icu_stays\n",
    "#     }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e672c18c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resp_f.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# resp_f = process_resp_support_waterfall(resp)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m resp_f \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresp_f.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/clif/CLIF-epi-of-sedation/.venv-sedation/lib/python3.10/site-packages/pandas/io/parquet.py:669\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    667\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/clif/CLIF-epi-of-sedation/.venv-sedation/lib/python3.10/site-packages/pandas/io/parquet.py:258\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    257\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    266\u001b[0m         path_or_handle,\n\u001b[1;32m    267\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    271\u001b[0m     )\n",
      "File \u001b[0;32m~/code/clif/CLIF-epi-of-sedation/.venv-sedation/lib/python3.10/site-packages/pandas/io/parquet.py:141\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    131\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/code/clif/CLIF-epi-of-sedation/.venv-sedation/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resp_f.parquet'"
     ]
    }
   ],
   "source": [
    "# resp_f = process_resp_support_waterfall(resp)\n",
    "resp_f = pd.read_parquet(\"resp_f.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_hosp_ids = [\n",
    "    '21738444', \n",
    "    '20004088', \n",
    "    '20006154', \n",
    "    '20018306'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"\"\"\n",
    "# SELECT SUM(CASE WHEN location_category = 'icu' THEN 1 ELSE 0 END) as total_icu_stays\n",
    "# FROM adt\n",
    "# WHERE hospitalization_id IN ({\",\".join(focal_hosp_ids)})\n",
    "# \"\"\"\n",
    "# duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_f['date_hr'] = resp_f['recorded_dttm'].dt.floor('h')\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT t1.hospitalization_id\n",
    "    , t3.encounter_block\n",
    "    , t1.date_hr\n",
    "    , MAX(CASE WHEN t2.new_icu_stay = 1 THEN 1 ELSE 0 END) as new_icu_start_from_adt\n",
    "    , MAX(CASE WHEN t1.device_category = 'imv' THEN 1 ELSE 0 END) as on_imv\n",
    "    , MAX(CASE WHEN t1.tracheostomy is True OR t1.tracheostomy = 1 THEN 1 ELSE 0 END) as trach_ever\n",
    "    , ROW_NUMBER() OVER (PARTITION BY t1.hospitalization_id ORDER BY t1.date_hr) as rn_by_hosp\n",
    "    , CASE WHEN (\n",
    "        rn_by_hosp = 1 -- new hospitalization\n",
    "        OR new_icu_start_from_adt = 1 -- new icu stay\n",
    "    ) THEN 1 ELSE 0 END as new_icu_stay\n",
    "FROM resp_f as t1\n",
    "LEFT JOIN new_icu_start_hours AS t2\n",
    "    ON t1.hospitalization_id = t2.hospitalization_id\n",
    "    AND t1.date_hr = t2.in_date_hr\n",
    "LEFT JOIN hosp_to_enc_blk_mapper AS t3\n",
    "    ON t1.hospitalization_id = t3.hospitalization_id\n",
    "-- WHERE t1.hospitalization_id IN ({\",\".join(focal_hosp_ids)})\n",
    "GROUP BY t1.hospitalization_id, t1.date_hr, t3.encounter_block\n",
    "ORDER BY t1.hospitalization_id, t1.date_hr\n",
    "\"\"\"\n",
    "df1 = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "-- generate unique icu stay ids\n",
    "WITH t1 AS (\n",
    "    SELECT hospitalization_id\n",
    "        , encounter_block\n",
    "        , date_hr\n",
    "        , on_imv\n",
    "        , new_icu_stay\n",
    "        , SUM(new_icu_stay) OVER (ORDER BY hospitalization_id, date_hr) as icu_stay_id\n",
    "    FROM df1\n",
    "    -- keep only hospitalizations that have at least one hour on imv and no tracheostomy\n",
    "    WHERE hospitalization_id IN (\n",
    "        SELECT DISTINCT hospitalization_id\n",
    "        FROM df1\n",
    "        GROUP BY hospitalization_id\n",
    "        HAVING MAX(on_imv) = 1 AND MAX(trach_ever) = 0\n",
    "    )\n",
    "),\n",
    "-- generate unique imv streak ids\n",
    "t2 AS (\n",
    "    SELECT hospitalization_id\n",
    "        , icu_stay_id\n",
    "        -- , encounter_block\n",
    "        , date_hr\n",
    "        , on_imv\n",
    "        , ROW_NUMBER() OVER (PARTITION BY icu_stay_id ORDER BY date_hr) as rn_overall\n",
    "        , ROW_NUMBER() OVER (PARTITION BY icu_stay_id, on_imv ORDER BY date_hr) as rn_by_imv_status\n",
    "        , rn_overall - rn_by_imv_status as imv_streak_id\n",
    "    FROM t1\n",
    "    -- keep only icu stays that have at least one hour on imv\n",
    "    WHERE icu_stay_id IN (\n",
    "        SELECT DISTINCT icu_stay_id\n",
    "        FROM t1\n",
    "        GROUP BY icu_stay_id\n",
    "        HAVING MAX(on_imv) = 1\n",
    "    )\n",
    "    ORDER BY hospitalization_id, icu_stay_id, date_hr\n",
    "),\n",
    "-- mark the 24th and 72th hour of each imv streak\n",
    "t3 AS (\n",
    "    SELECT hospitalization_id, icu_stay_id, date_hr\n",
    "        , imv_streak_id, on_imv\n",
    "        , SUM(on_imv) OVER (PARTITION BY icu_stay_id, imv_streak_id ORDER BY date_hr) as imv_hrs_in_streak\n",
    "        , CASE WHEN (imv_hrs_in_streak = 24) THEN 1 ELSE 0 END as hr_24_on_imv\n",
    "        , CASE WHEN (imv_hrs_in_streak = 72) THEN 1 ELSE 0 END as hr_72_on_imv\n",
    "        -- calculate hour since first intubation within each icu stay\n",
    "        , MIN(CASE WHEN on_imv = 1 THEN date_hr END) OVER (PARTITION BY icu_stay_id) as first_imv_hr_in_icu_stay\n",
    "        -- can only calculate diff in secs, so convert to hrs\n",
    "        ,  EXTRACT(EPOCH FROM (date_hr - first_imv_hr_in_icu_stay)) / 3600 + 1 as hrs_since_first_imv\n",
    "    FROM t2\n",
    "    ORDER BY hospitalization_id, icu_stay_id, date_hr\n",
    "    )\n",
    "-- exclude cases with reintubation within 72 hours\n",
    "SELECT hospitalization_id, icu_stay_id, date_hr\n",
    "    , imv_streak_id, on_imv, imv_hrs_in_streak, hrs_since_first_imv\n",
    "    , hr_24_on_imv, hr_72_on_imv\n",
    "    , COUNT(DISTINCT CASE WHEN hrs_since_first_imv BETWEEN 0 AND 72 THEN imv_streak_id END) \n",
    "        OVER (PARTITION BY icu_stay_id) as n_imv_streaks_in_72_hrs\n",
    "    , CASE WHEN n_imv_streaks_in_72_hrs <= 2 AND hr_24_on_imv = 1 THEN 1 ELSE 0 END as hr_24_on_imv_noreintub\n",
    "    , CASE WHEN n_imv_streaks_in_72_hrs = 1 AND hr_72_on_imv = 1 THEN 1 ELSE 0 END as hr_72_on_imv_noreintub\n",
    "FROM t3\n",
    "ORDER BY hospitalization_id, icu_stay_id, date_hr\n",
    "\"\"\"\n",
    "df2 = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7da8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%ipytest` not found.\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "# sanity tests against the MIMIC-IV data\n",
    "@pytest.mark.parametrize(\"hospitalization_id,date_hr,expected_hr,expected_flag,expected_flag_noreintub\", [\n",
    "    # on imv for 24-hrs twice during the same hospitalization -- so would be excluded if no reintubation within 72 hrs\n",
    "    (21738444, \"2186-09-14 17:00:00-06:00\", 24, 1, 0),  \n",
    "    (21738444, \"2186-09-14 18:00:00-06:00\", 24, 0, 0),  \n",
    "    (21738444, \"2186-09-16 18:00:00-06:00\", 24, 1, 0), # second streak within the hosp\n",
    "    # not on imv for the first few hrs but long streak afterwards\n",
    "    (20004088, \"2159-09-30 09:00:00-06:00\", 24, 1, 1),\n",
    "    (20004088, \"2159-10-02 09:00:00-06:00\", 72, 1, 1),\n",
    "    # very short streaks: 20006154\n",
    "    # 3 icu stays within the same hospitalization\n",
    "    (20018306, \"2136-05-16 05:00:00-06:00\", 24, 1, 1),\n",
    "    (20018306, \"2136-07-01 19:00:00-06:00\", 24, 1, 1),\n",
    "    # (20018306, \"2136-06-01 03:00:00-06:00\", 24, 0), # in a icu stay that was filtered out in the df because of no imv ever\n",
    "])\n",
    "def test_if_on_imv_at_hr_x(hospitalization_id, date_hr, expected_hr, expected_flag, expected_flag_noreintub):\n",
    "    query = f\"\"\"\n",
    "    SELECT hr_{expected_hr}_on_imv, hr_{expected_hr}_on_imv_noreintub\n",
    "    FROM df2\n",
    "    WHERE hospitalization_id = {hospitalization_id}\n",
    "    AND date_hr = '{date_hr}'\n",
    "    \"\"\"\n",
    "    result = duckdb.sql(query).to_df()\n",
    "    observed_flag = result[f'hr_{expected_hr}_on_imv'].iloc[0]\n",
    "    observed_flag_noreintub = result[f'hr_{expected_hr}_on_imv_noreintub'].iloc[0]\n",
    "    assert observed_flag == expected_flag\n",
    "    assert observed_flag_noreintub == expected_flag_noreintub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac0635a",
   "metadata": {},
   "source": [
    "### The Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the cohort\n",
    "query = \"\"\"\n",
    "SELECT hospitalization_id\n",
    "    , encounter_block\n",
    "    --, icu_stay_id\n",
    "    , date_hr\n",
    "    , CASE WHEN hr_24_on_imv_noreintub = 1 THEN 'hr_24'\n",
    "        WHEN hr_72_on_imv_noreintub = 1 THEN 'hr_72'\n",
    "        ELSE NULL END as cohort_flag\n",
    "FROM df2\n",
    "LEFT JOIN hosp_to_enc_blk_mapper USING (hospitalization_id)\n",
    "WHERE hr_24_on_imv_noreintub = 1 OR hr_72_on_imv_noreintub = 1\n",
    "\"\"\"\n",
    "cohort = duckdb.sql(query).to_df()\n",
    "\n",
    "cohort_hosp_ids = cohort['hospitalization_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65870fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "    , \n",
    "FROM cohort\n",
    "WHERE cohort_flag IS NOT NULL AND med_category is NOT NULL\n",
    "\"\"\"\n",
    "mac_cohort_hrs = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4cd8cf",
   "metadata": {},
   "source": [
    "## Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "24a7d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_categories = [\n",
    "    \"weight_kg\",\n",
    "    \"height_cm\",\n",
    "    \"temp_c\"\n",
    "    \"heart_rate\",\n",
    "    \"respiratory_rate\",\n",
    "    \"temperature\",\n",
    "    \"sbp\",\n",
    "    \"dbp\",\n",
    "    \"spo2\",\n",
    "    \"map\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "203eaa0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: Referenced column \"vital_categories\" not found in FROM clause!\nCandidate bindings: \"hospitalization_id\", \"date_hr\", \"cohort_flag\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBinderException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mSELECT *,\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    UNNEST(vital_categories) as vital_category\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mFROM cohort\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mduckdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_df()\n",
      "\u001b[0;31mBinderException\u001b[0m: Binder Error: Referenced column \"vital_categories\" not found in FROM clause!\nCandidate bindings: \"hospitalization_id\", \"date_hr\", \"cohort_flag\""
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT *,\n",
    "    UNNEST(vital_categories) as vital_category\n",
    "FROM cohort\n",
    "\"\"\"\n",
    "duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4200b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/wliao0504/code/clif/CLIF-MIMIC/output/rclif-dev-test-copy/clif_vitals.parquet\n"
     ]
    }
   ],
   "source": [
    "vitals_required_columns = [\n",
    "    \"hospitalization_id\",\n",
    "    \"recorded_dttm\",\n",
    "    \"vital_category\",\n",
    "    \"vital_value\"\n",
    "]\n",
    "\n",
    "vitals = pc.load_data(\n",
    "    table = \"clif_vitals\",\n",
    "    filters = {\n",
    "        \"hospitalization_id\": cohort_hosp_ids\n",
    "    },\n",
    "    columns = vitals_required_columns\n",
    ")\n",
    "\n",
    "vitals['date_hr'] = vitals['recorded_dttm'].dt.floor('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330757c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "-- fill any missing values in the cohort hours with the nearest in time (in the past or future)\n",
    "SELECT hospitalization_id\n",
    "    , date_hr\n",
    "    , cohort_flag\n",
    "    , vital_category\n",
    "    , MEAN(vital_value) as mean_value\n",
    "    /*\n",
    "    , LAG(mean_value) OVER (PARTITION BY hospitalization_id, date_hr, vital_category ORDER BY date_hr) as mean_value_last\n",
    "    , LAG(date_hr) OVER (PARTITION BY hospitalization_id, vital_category ORDER BY date_hr) as date_hr_last\n",
    "    , (date_hr - date_hr_last) as distance_to_last\n",
    "    , LEAD(mean_value) OVER (PARTITION BY hospitalization_id, date_hr, vital_category ORDER BY date_hr) as mean_value_next\n",
    "    , LEAD(date_hr) OVER (PARTITION BY hospitalization_id, vital_category ORDER BY date_hr) as date_hr_next\n",
    "    , (date_hr_next - date_hr) as distance_to_next\n",
    "    , CASE WHEN distance_to_last < distance_to_next THEN mean_value_last ELSE mean_value_next END as mean_value_nearest\n",
    "    , COALESCE(mean_value, mean_value_nearest) as mean_value_final\n",
    "    */\n",
    "FROM cohort\n",
    "FULL OUTER JOIN vitals USING (hospitalization_id, date_hr)\n",
    "GROUP BY hospitalization_id, date_hr, cohort_flag, vital_category\n",
    "ORDER BY hospitalization_id, vital_category, date_hr, cohort_flag\n",
    "\"\"\"\n",
    "vitals_hrly = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc7b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT hospitalization_id\n",
    "    , date_hr\n",
    "    , cohort_flag\n",
    "    , vital_category\n",
    "    , mean_value\n",
    "    , mean_value_final\n",
    "FROM vitals_hrly\n",
    "WHERE cohort_flag IS NOT NULL\n",
    "ORDER BY hospitalization_id, vital_category, date_hr, cohort_flag\n",
    "\"\"\"\n",
    "vitals_cohort_hrs = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac250e05",
   "metadata": {},
   "source": [
    "## Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2422daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/wliao0504/code/clif/CLIF-MIMIC/output/rclif-dev-test-copy/clif_medication_admin_continuous.parquet\n"
     ]
    }
   ],
   "source": [
    "sed_med_categories = [\n",
    "    \"midazolam\", \"lorazepam\", \"hydromorphone\", \"fentanyl\", \"propofol\", \"dexmedetomidine\", \"ketamine\"\n",
    "]\n",
    "\n",
    "mac_required_columns = [\n",
    "    \"hospitalization_id\", \n",
    "    \"admin_dttm\",\n",
    "    \"med_category\",\n",
    "    \"med_dose\",\n",
    "    \"med_dose_unit\",\n",
    "    \"mar_action_name\"\n",
    "]\n",
    "\n",
    "mac = pc.load_data(\n",
    "    table = \"clif_medication_admin_continuous\",\n",
    "    columns = mac_required_columns,\n",
    "    filters = {\n",
    "        \"hospitalization_id\": cohort_hosp_ids,\n",
    "        \"med_category\": sed_med_categories\n",
    "    }\n",
    ")\n",
    "\n",
    "mac['date_hr'] = mac['admin_dttm'].dt.floor('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4dc26",
   "metadata": {},
   "source": [
    "### Check dosage unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c32b057d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_category</th>\n",
       "      <th>med_dose_unit</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dexmedetomidine</td>\n",
       "      <td>mcg/kg/hour</td>\n",
       "      <td>89430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fentanyl</td>\n",
       "      <td>mcg/hour</td>\n",
       "      <td>113807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fentanyl</td>\n",
       "      <td>mcg/kg/hour</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hydromorphone</td>\n",
       "      <td>mg/hour</td>\n",
       "      <td>9356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ketamine</td>\n",
       "      <td>mg/kg/hour</td>\n",
       "      <td>7513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ketamine</td>\n",
       "      <td>mg/hour</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ketamine</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ketamine</td>\n",
       "      <td>mcg/min</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lorazepam</td>\n",
       "      <td>mg/hour</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>midazolam</td>\n",
       "      <td>mg/hour</td>\n",
       "      <td>46571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>propofol</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>245979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>propofol</td>\n",
       "      <td>mg/hour</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       med_category med_dose_unit       n\n",
       "0   dexmedetomidine   mcg/kg/hour   89430\n",
       "1          fentanyl      mcg/hour  113807\n",
       "2          fentanyl   mcg/kg/hour       2\n",
       "3     hydromorphone       mg/hour    9356\n",
       "4          ketamine    mg/kg/hour    7513\n",
       "5          ketamine       mg/hour     101\n",
       "6          ketamine    mcg/kg/min      33\n",
       "7          ketamine       mcg/min      11\n",
       "8         lorazepam       mg/hour     128\n",
       "9         midazolam       mg/hour   46571\n",
       "10         propofol    mcg/kg/min  245979\n",
       "11         propofol       mg/hour       2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT med_category, med_dose_unit, COUNT(*) as n\n",
    "FROM mac\n",
    "GROUP BY med_category, med_dose_unit\n",
    "ORDER BY med_category, n DESC\n",
    "\"\"\"\n",
    "med_units_count = duckdb.sql(query).to_df()\n",
    "med_units_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4df3b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT c.hospitalization_id\n",
    "    , c.cohort_flag\n",
    "    , med_category\n",
    "    , c.date_hr\n",
    "    , LAG(admin_dttm) OVER (PARTITION BY c.hospitalization_id, med_category ORDER BY admin_dttm) as admin_dttm_last\n",
    "    , LAG(med_dose) OVER (PARTITION BY c.hospitalization_id, med_category ORDER BY admin_dttm) as med_dose_last\n",
    "    , admin_dttm\n",
    "    , med_dose\n",
    "    , med_dose_unit\n",
    "    , mar_action_name\n",
    "    , mean_value_final as weight_kg\n",
    "FROM cohort c\n",
    "LEFT JOIN vitals_cohort_hrs v \n",
    "    ON c.hospitalization_id = v.hospitalization_id\n",
    "    AND c.date_hr = v.date_hr\n",
    "    AND v.vital_category = 'weight_kg'\n",
    "FULL OUTER JOIN mac m \n",
    "    ON c.hospitalization_id = m.hospitalization_id\n",
    "    AND c.date_hr = m.date_hr\n",
    "ORDER BY c.hospitalization_id, c.date_hr, admin_dttm, med_category, c.cohort_flag\n",
    "\"\"\"\n",
    "mac_hrly = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4d77797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "    , CASE WHEN admin_dttm = MIN(admin_dttm) OVER (PARTITION BY hospitalization_id, med_category, date_hr) \n",
    "        THEN 1 ELSE 0 END as is_first_streak\n",
    "    , CASE WHEN admin_dttm = MAX(admin_dttm) OVER (PARTITION BY hospitalization_id, med_category, date_hr) \n",
    "        THEN 1 ELSE 0 END as is_last_streak\n",
    "    , date_hr + INTERVAL '1 hour' as date_hr_next\n",
    "FROM mac_hrly\n",
    "WHERE cohort_flag IS NOT NULL AND med_category is NOT NULL\n",
    "ORDER BY hospitalization_id, med_category, date_hr, admin_dttm\n",
    "\"\"\"\n",
    "mac_cohort_hrs = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97cf627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT hospitalization_id, cohort_flag, med_category, date_hr\n",
    "    , SUM(CASE \n",
    "        WHEN is_first_streak != 1 \n",
    "            THEN EXTRACT(EPOCH FROM (admin_dttm - admin_dttm_last))/60.0 * med_dose_last \n",
    "        WHEN is_first_streak = 1\n",
    "        THEN EXTRACT(EPOCH FROM (admin_dttm - date_hr))/60.0 * med_dose_last \n",
    "        WHEN is_last_streak = 1\n",
    "            THEN EXTRACT(EPOCH FROM (date_hr_next - admin_dttm))/60.0 * med_dose_last\n",
    "        ELSE 0 END) as total_dosage\n",
    "FROM mac_cohort_hrs\n",
    "GROUP BY hospitalization_id, med_category, date_hr, cohort_flag\n",
    "\"\"\"\n",
    "mac_cohort_dosage = duckdb.sql(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a5fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-sedation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
